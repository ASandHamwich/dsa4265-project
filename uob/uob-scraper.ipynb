{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9mwXuqpjSMR",
        "outputId": "4451dc75-61fa-463f-c39e-f94cd782328e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.1)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.31.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,383 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,824 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,000 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n",
            "Fetched 26.0 MB in 4s (6,957 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 1s (44.3 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126213 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126413 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 126642 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.15) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2025.1.31)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.1.0 webdriver-manager-4.0.2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-chromedriver\n",
        "!pip install webdriver-manager\n",
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "import csv\n",
        "import logging\n",
        "import os\n",
        "import queue\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import html\n",
        "\n",
        "class UOBScraper:\n",
        "    def __init__(self, headless=True, output_dir=\"uob_data\", max_workers=5):\n",
        "        self.output_dir = output_dir\n",
        "        self.max_workers = max_workers  # Number of parallel workers\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        self.options = Options()\n",
        "        if headless:\n",
        "            self.options.add_argument(\"--headless\")\n",
        "        self.options.add_argument(\"--disable-gpu\")\n",
        "        self.options.add_argument(\"--no-sandbox\")\n",
        "        self.options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        self.options.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "        # Create a lock for thread-safe operations\n",
        "        self.data_lock = threading.Lock()\n",
        "\n",
        "        # Initialize empty data list\n",
        "        self.data = []\n",
        "\n",
        "        # Cache of visited URLs to avoid duplicated work\n",
        "        self.visited_urls = set()\n",
        "\n",
        "        # Setup cleaning patterns\n",
        "        self._setup_cleaning_patterns()\n",
        "\n",
        "    def _setup_cleaning_patterns(self):\n",
        "        # Expanded list of boilerplate patterns\n",
        "        self.boilerplate_patterns = [\n",
        "            r\"Terms and Conditions Apply\",\n",
        "            r\"Click here.*\",\n",
        "            r\"Learn More\",\n",
        "            r\"Read more.*\",\n",
        "            r\"Like us on Facebook\",\n",
        "            r\"Follow us on Twitter\",\n",
        "            r\"Back to Top\",\n",
        "            r\"\\*Terms and conditions apply.*\",\n",
        "            r\"Back to Main.*\",\n",
        "            r\"HOME\",\n",
        "            r\"UOB Singapore\",\n",
        "            r\"Current Promotions\",\n",
        "            r\"Customer Service\",\n",
        "            r\"Share Your Experiences\",\n",
        "            r\"Copyright © \\d{4} United Overseas Bank Limited\",\n",
        "            r\"Co\\. Reg\\. No\\. \\d+Z\\. All Rights Reserved\\.\",\n",
        "            r\"We use cookies in order to provide you with better services.*\",\n",
        "            r\"By continuing to browse the site, you agree to our privacy notice and cookie policy\\.\",\n",
        "            r\"privacy notice\",\n",
        "            r\"cookie policy\",\n",
        "            r\"Back to MainHOME\",\n",
        "            r\"Back to MainSave\",\n",
        "            r\"Back to MainCards\",\n",
        "            r\"Back to MainBorrow\",\n",
        "            r\"Back to MainInvest\",\n",
        "            r\"Back to MainInsure\",\n",
        "            r\"Back to MainDigital Banking\",\n",
        "        ]\n",
        "\n",
        "        # Encoding fix map\n",
        "        self.encoding_fix_map = {\n",
        "            \"â€™\": \"'\",   # Right single quotation mark\n",
        "            \"â€œ\": '\"',   # Left double quotation mark\n",
        "            \"â€\": '\"',    # Right double quotation mark\n",
        "            \"â€\": \"–\",   # En dash\n",
        "            \"â€¢\": \"•\",   # Bullet\n",
        "            \"Ã©\": \"é\",    # Latin small letter e with acute\n",
        "            \"Ã¨\": \"è\",    # Latin small letter e with grave\n",
        "            \"Ã \": \"à\",    # Latin small letter a with grave\n",
        "            \"Ã¢\": \"â\",    # Latin small letter a with circumflex\n",
        "            \"Ã¤\": \"ä\",    # Latin small letter a with diaeresis\n",
        "            \"Ã«\": \"ë\",    # Latin small letter e with diaeresis\n",
        "            \"Ã¯\": \"ï\",    # Latin small letter i with diaeresis\n",
        "            \"Ã´\": \"ô\",    # Latin small letter o with circumflex\n",
        "            \"Ã¶\": \"ö\",    # Latin small letter o with diaeresis\n",
        "            \"Ã¹\": \"ù\",    # Latin small letter u with grave\n",
        "            \"Ã»\": \"û\",    # Latin small letter u with circumflex\n",
        "            \"Ã¼\": \"ü\",    # Latin small letter u with diaeresis\n",
        "            \"Ã§\": \"ç\",    # Latin small letter c with cedilla\n",
        "            \"Â£\": \"£\",    # Pound sign\n",
        "            \"Â€\": \"€\",    # Euro sign\n",
        "            \"Â©\": \"©\",    # Copyright sign\n",
        "            \"Â®\": \"®\",    # Registered sign\n",
        "            \"â„¢\": \"™\"    # Trademark sign\n",
        "        }\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # First decode HTML entities\n",
        "        text = html.unescape(text)\n",
        "\n",
        "        # Replace unwanted whitespace and non-breaking spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        text = text.replace('\\xa0', ' ')\n",
        "\n",
        "        # Fix encoding issues based on our mapping\n",
        "        for wrong, correct in self.encoding_fix_map.items():\n",
        "            text = text.replace(wrong, correct)\n",
        "\n",
        "        # Apply additional Unicode normalization\n",
        "        import unicodedata\n",
        "        text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "        # Remove boilerplate texts using more aggressive pattern matching\n",
        "        for pattern in self.boilerplate_patterns:\n",
        "            text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Remove menu navigation text patterns\n",
        "        text = re.sub(r'Back to \\w+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Final whitespace cleanup\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def is_valid_text(self, text):\n",
        "        # More aggressive filtering of unwanted content\n",
        "        if not text or len(text.strip()) <= 10:\n",
        "            return False\n",
        "\n",
        "        # Skip common footer/header/navigation text patterns\n",
        "        unwanted_phrases = [\n",
        "            \"back to main\", \"copyright\", \"all rights reserved\",\n",
        "            \"terms and conditions\", \"privacy policy\", \"cookie policy\",\n",
        "            \"customer service\", \"promotions\", \"share your experiences\"\n",
        "        ]\n",
        "\n",
        "        lower_text = text.lower()\n",
        "        for phrase in unwanted_phrases:\n",
        "            if phrase in lower_text:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def extract_metadata_tags(self, url):\n",
        "        tags = []\n",
        "        if \"insure\" in url: tags.append(\"insurance\")\n",
        "        if \"loan\" in url or \"borrow\" in url: tags.append(\"loans\")\n",
        "        if \"card\" in url: tags.append(\"credit cards\")\n",
        "        if \"save\" in url: tags.append(\"savings\")\n",
        "        if \"invest\" in url: tags.append(\"investments\")\n",
        "        if \"digital-banking\" in url: tags.append(\"digital banking\")\n",
        "        if \"wealth\" in url: tags.append(\"wealth management\")\n",
        "        if \"banking\" in url: tags.append(\"banking\")\n",
        "        return \", \".join(tags) if tags else \"general\"\n",
        "\n",
        "    def is_valid_url(self, url, base_url=None):\n",
        "        \"\"\"Check if URL should be processed based on content relevance.\"\"\"\n",
        "        if not url or url.startswith(\"javascript:\"):\n",
        "            return False\n",
        "\n",
        "        # Convert relative URLs to absolute\n",
        "        if base_url and url.startswith(\"/\"):\n",
        "            url = urljoin(base_url, url)\n",
        "\n",
        "        # Filter by domain\n",
        "        if \"uob.com.sg\" not in url:\n",
        "            return False\n",
        "\n",
        "        # Skip URLs that are already processed\n",
        "        if url in self.visited_urls:\n",
        "            return False\n",
        "\n",
        "        # Skip URLs that are not related to banking products\n",
        "        if \"personal\" not in url:\n",
        "            return False\n",
        "\n",
        "        # Skip file downloads\n",
        "        if any(url.endswith(ext) for ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip']):\n",
        "            return False\n",
        "\n",
        "        # Skip irrelevant sections\n",
        "        skip_sections = ['careers', 'about', 'contact', 'newsroom', 'media', 'sustainability']\n",
        "        if any(section in url for section in skip_sections):\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def scrape_page_with_driver(self, driver, url):\n",
        "        \"\"\"Scrape a single page using the provided driver.\"\"\"\n",
        "        try:\n",
        "            # Mark URL as visited to avoid reprocessing\n",
        "            self.visited_urls.add(url)\n",
        "\n",
        "            # Try to navigate to the URL with a short timeout\n",
        "            driver.get(url)\n",
        "\n",
        "            try:\n",
        "                # More efficient wait strategy: wait for specific elements that indicate page load\n",
        "                WebDriverWait(driver, 5).until(\n",
        "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
        "                )\n",
        "            except TimeoutException:\n",
        "                logging.warning(f\"Timeout waiting for page to load: {url}\")\n",
        "                return [], []  # FIXED: Return two empty lists instead of one\n",
        "\n",
        "            # No need for fixed sleep - wait for elements instead\n",
        "\n",
        "            # Set page encoding to UTF-8\n",
        "            driver.execute_script(\"document.charset='utf-8';\")\n",
        "\n",
        "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Extract title from h1 or page title\n",
        "            title_element = soup.find(\"h1\")\n",
        "            title = self.clean_text(title_element.get_text()) if title_element else self.clean_text(driver.title)\n",
        "\n",
        "            # Attempt to extract a subtitle (h2 tag following the h1)\n",
        "            subtitle = \"\"\n",
        "            if title_element and title_element.find_next(\"h2\"):\n",
        "                subtitle = self.clean_text(title_element.find_next(\"h2\").get_text())\n",
        "\n",
        "            # Extract metadata tags from URL\n",
        "            tag = self.extract_metadata_tags(url)\n",
        "\n",
        "            # Collect page data\n",
        "            page_data = []\n",
        "\n",
        "            # Extract content from paragraphs and list items\n",
        "            for section in soup.find_all(['p', 'li']):\n",
        "                # Skip elements within navigation or footer sections\n",
        "                if any(parent_tag in [parent.name for parent in section.parents] for parent_tag in ['nav', 'footer']):\n",
        "                    continue\n",
        "\n",
        "                # Skip elements with certain classes or IDs\n",
        "                skip_classes = ['footer', 'navigation', 'menu', 'copyright', 'legal']\n",
        "                if any(cls in section.get('class', []) for cls in skip_classes):\n",
        "                    continue\n",
        "\n",
        "                text = self.clean_text(section.get_text())\n",
        "                if self.is_valid_text(text):\n",
        "                    page_data.append({\n",
        "                        \"url\": url,\n",
        "                        \"title\": title,\n",
        "                        \"subtitle\": subtitle,\n",
        "                        \"subheader\": title,\n",
        "                        \"text\": text,\n",
        "                        \"tag\": tag\n",
        "                    })\n",
        "\n",
        "            # Find links for further crawling\n",
        "            links = []\n",
        "            for a in soup.find_all(\"a\", href=True):\n",
        "                try:\n",
        "                    link = a[\"href\"]\n",
        "                    # Convert relative URLs to absolute\n",
        "                    if link.startswith(\"/\"):\n",
        "                        link = urljoin(url, link)\n",
        "                    # Only collect valid UOB URLs\n",
        "                    if self.is_valid_url(link, url):\n",
        "                        links.append(link)\n",
        "                except (KeyError, AttributeError):\n",
        "                    continue\n",
        "\n",
        "            return page_data, links\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error scraping {url}: {e}\")\n",
        "            return [], []  # Return two empty lists if there's an exception\n",
        "\n",
        "    def scrape_page(self, url):\n",
        "        \"\"\"Scrape a single page with a new driver instance.\"\"\"\n",
        "        driver = webdriver.Chrome(options=self.options)\n",
        "        try:\n",
        "            page_data, _ = self.scrape_page_with_driver(driver, url)\n",
        "\n",
        "            # Thread-safe addition of data\n",
        "            with self.data_lock:\n",
        "                self.data.extend(page_data)\n",
        "\n",
        "            return page_data\n",
        "        finally:\n",
        "            driver.quit()\n",
        "\n",
        "    def scrape_urls(self, urls):\n",
        "        \"\"\"Scrape a provided list of URLs in parallel.\"\"\"\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            # Submit all URL scraping tasks\n",
        "            futures = [executor.submit(self.scrape_page, url) for url in urls]\n",
        "\n",
        "            # Process results as they complete\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    # Results are processed in the scrape_page method\n",
        "                    future.result()\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error in parallel scraping: {e}\")\n",
        "\n",
        "        # Process data after all scraping is complete\n",
        "        self.post_process_data()\n",
        "\n",
        "    def scrape_deep_section(self, base_url, max_depth=1):\n",
        "        \"\"\"\n",
        "        Efficiently scrape a section using breadth-first crawling with parallel processing.\n",
        "        Uses a queue-based approach instead of recursion for better performance.\n",
        "        \"\"\"\n",
        "        # Initialize a driver for this section\n",
        "        driver = webdriver.Chrome(options=self.options)\n",
        "\n",
        "        try:\n",
        "            # Use a queue for breadth-first traversal\n",
        "            url_queue = queue.Queue()\n",
        "            url_queue.put((base_url, 0))  # (url, depth)\n",
        "\n",
        "            # Keep track of URLs we've queued to avoid duplicates\n",
        "            queued_urls = {base_url}\n",
        "\n",
        "            # Process URLs in breadth-first order\n",
        "            while not url_queue.empty():\n",
        "                current_url, depth = url_queue.get()\n",
        "\n",
        "                # Skip if we've reached max depth\n",
        "                if depth > max_depth:\n",
        "                    continue\n",
        "\n",
        "                # Mark as visited\n",
        "                self.visited_urls.add(current_url)\n",
        "\n",
        "                # Scrape the page\n",
        "                page_data, links = self.scrape_page_with_driver(driver, current_url)\n",
        "\n",
        "                # Thread-safe addition of data\n",
        "                with self.data_lock:\n",
        "                    self.data.extend(page_data)\n",
        "\n",
        "                # Add child links to queue if within depth limit\n",
        "                if depth < max_depth:\n",
        "                    # Filter links to only include relevant ones\n",
        "                    relevant_links = []\n",
        "                    for link in links:\n",
        "                        # Apply additional filtering for deeper crawls\n",
        "                        if depth > 0:\n",
        "                            # Only include pages that are likely product pages\n",
        "                            keywords = ['card', 'insure', 'invest', 'save', 'loan', 'borrow', 'wealth']\n",
        "                            if not any(keyword in link.lower() for keyword in keywords):\n",
        "                                continue\n",
        "\n",
        "                        # Add if not already queued\n",
        "                        if link not in queued_urls:\n",
        "                            relevant_links.append(link)\n",
        "                            queued_urls.add(link)\n",
        "\n",
        "                    # Add filtered links to queue\n",
        "                    for link in relevant_links:\n",
        "                        url_queue.put((link, depth + 1))\n",
        "\n",
        "                    # Don't overload the server - small delay between batches\n",
        "                    if len(relevant_links) > 0:\n",
        "                        time.sleep(0.2)\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in deep scraping {base_url}: {e}\")\n",
        "        finally:\n",
        "            driver.quit()\n",
        "\n",
        "    def scrape_deep_sections_parallel(self, base_urls, max_depth=2):\n",
        "        \"\"\"Scrape multiple sections in parallel.\"\"\"\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            # Create a future for each base URL\n",
        "            futures = [\n",
        "                executor.submit(self.scrape_deep_section, url, max_depth)\n",
        "                for url in base_urls\n",
        "            ]\n",
        "\n",
        "            # Wait for all futures to complete\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    future.result()\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error in parallel deep scraping: {e}\")\n",
        "\n",
        "        # Process all collected data\n",
        "        self.post_process_data()\n",
        "\n",
        "    def post_process_data(self):\n",
        "        \"\"\"Process and save the collected data.\"\"\"\n",
        "        if not self.data:\n",
        "            logging.warning(\"No data collected to process.\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.data)\n",
        "\n",
        "        # Apply cleaning to all text columns to ensure consistency\n",
        "        for col in ['title', 'subtitle', 'subheader', 'text']:\n",
        "            df[col] = df[col].apply(lambda x: self.clean_text(str(x)) if pd.notna(x) else '')\n",
        "\n",
        "        # Filter out invalid entries and duplicates\n",
        "        df = df[df['text'].apply(self.is_valid_text)]\n",
        "        df = df.drop_duplicates(subset=['text'])\n",
        "\n",
        "        # Additional filtering for unwanted content patterns\n",
        "        def contains_unwanted_patterns(text):\n",
        "            unwanted_patterns = [\n",
        "                r'back to main',\n",
        "                r'copyright',\n",
        "                r'all rights reserved',\n",
        "                r'privacy notice',\n",
        "                r'cookie policy',\n",
        "                r'united overseas bank'\n",
        "            ]\n",
        "\n",
        "            for pattern in unwanted_patterns:\n",
        "                if re.search(pattern, text, re.IGNORECASE):\n",
        "                    return True\n",
        "            return False\n",
        "\n",
        "        df = df[~df['text'].apply(contains_unwanted_patterns)]\n",
        "\n",
        "        # Sort by URL and subheader\n",
        "        df = df.sort_values(['url', 'subheader'])\n",
        "\n",
        "        # Save to CSV with explicit UTF-8 encoding\n",
        "        output_file = f\"{self.output_dir}/uob_data_cleaned.csv\"\n",
        "\n",
        "        # Using pandas to write with appropriate encoding\n",
        "        df.to_csv(output_file, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)\n",
        "\n",
        "        # Also save to Excel as an alternative format that might handle encoding better\n",
        "        excel_file = f\"{self.output_dir}/uob_data_cleaned.xlsx\"\n",
        "        df.to_excel(excel_file, index=False, engine='openpyxl')\n",
        "\n",
        "        print(f\"Data successfully saved to {output_file} and {excel_file}\")\n",
        "        print(f\"Total entries: {len(df)}\")\n",
        "        print(f\"Total unique URLs scraped: {len(df['url'].unique())}\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Clean up resources.\"\"\"\n",
        "        pass  # Drivers are now managed per-thread\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Create the output directory first:\n",
        "    output_dir = \"uob_data\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # 2. Then configure logging, using the existing output directory:\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(os.path.join(output_dir, f\"scraper_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Manually placed URLs for the main categories\n",
        "    main_urls = [\n",
        "        \"https://www.uob.com.sg/personal/index.page\",                 # /personal/index.page\n",
        "        \"https://www.uob.com.sg/personal/finlit/index.page\",            # /personal/finlit/index.page\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/security/what-to-do-if-you-have-been-scammed/index.page\",  # /personal/digital-banking/pib/security/what-to-do-if-you-have-been-scammed/index.page\n",
        "        \"https://www.uob.com.sg/personal/save/protect-your-money.page\",   # /personal/save/protect-your-money.page\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/changes-to-sms-alerts.page\", # /personal/digital-banking/pib/changes-to-sms-alerts.page\n",
        "        \"https://www.uob.com.sg/personal/customer-service/index.page\",  # /personal/customer-service/index.page\n",
        "        \"https://www.uob.com.sg/personal/save/index.page\",             # /personal/save/index.page\n",
        "        \"https://www.uob.com.sg/personal/save/index.page?filter=everyday-use\",\n",
        "        \"https://www.uob.com.sg/personal/save/index.page?filter=consistent-saving\",\n",
        "        \"https://www.uob.com.sg/personal/save/index.page?filter=kids\",\n",
        "        \"https://www.uob.com.sg/personal/save/index.page?filter=foreign-currency\",\n",
        "        \"https://www.uob.com.sg/personal/save/index.page?filter=fixed-deposits\",\n",
        "        \"https://www.uob.com.sg/personal/save/everyday-accounts/one-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/savings-accounts/stash-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/foreign-currency-accounts/fxplus.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/savings-accounts/ladys-savings-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/everyday-accounts/krisflyer-uob-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/promotions/save/index.page?s_cid=grm:sg:owned:onl:pweb:oao:bu:na:casa:010425-300625:Q2SAVE25:na:na&vid=na&pid=CD07Q2SAVE25\",\n",
        "        \"https://www.uob.com.sg/personal/save/one-account-tax-saver.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/deputy-donee-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/save/services/egiro.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/merchant-services.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/news-and-announcements.page\",\n",
        "        \"https://www.uob.com.sg/personal/apply-now.page?filter=cards\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/personal-financing/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/car-financing/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/index.page#complete-your-loan-application\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/car-financing/index.page#loan-application\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/personal-financing/cashplus.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/personal-financing/personal-loan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/private-home-loan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/hdb-home-loan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/international-property-loan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/personal-financing/balance-transfer.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/personal-financing/debt-consolidation-plan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/managing-your-uob-property-loan.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/referral-programme.page\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/property-loans/private-home-loan.page#benefits\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/home-and-property/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/customer-service/loans.page#how-do-i-apply-for-a-car-loan\",\n",
        "        \"https://www.uob.com.sg/personal/borrow/bankers-guarantee.page\",\n",
        "        \"https://www.uob.com.sg/personal/apply-now.page?filter=loans\",\n",
        "        \"https://www.uob.com.sg/personal/invest/singapore-government-securities.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/unit-trusts/united-cio-funds.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/wealth-on-tmrw.page?s_cid=grm:sg:owned:pweb:investmegamenutile%20:na:bu:na:simpleinv:150823-evergreen:simpleinvest:na:na&vid=na\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/index.page#whats-new\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/index.page#other-features\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/index.page#tmrw-download-now\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/overview.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/index.page#services\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/security/how-uob-protects-you/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/phone-banking.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/nets-contactless.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/forgot-digital-username-or-password.page\",\n",
        "        \"https://www.uob.com.sg/personal/customer-service/tmrw-user-guide/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/customer-service/pib-tmrw/index.page\",\n",
        "        \"https://www.uob.com.sg/wealthbanking/index.page\",\n",
        "        \"https://www.uob.com.sg/privilegebanking/index.page\",\n",
        "        \"https://www.uob.com.sg/privilegereserve/index.page\",\n",
        "        \"https://www.uob.com.sg/private/index.page\",\n",
        "        \"https://www.uob.com.sg/business/index.page\",\n",
        "        \"https://www.uobgroup.com/foreign-direct-investment/index.page\",\n",
        "        \"https://www.uobgroup.com/asean-insights/index.page\",\n",
        "        \"https://www.uobgroup.com/industry-insights/index.page\",\n",
        "        \"https://www.uobgroup.com/sustainable-solutions/index.page\",\n",
        "        \"https://www.uobgroup.com/uobgroup/index.page\",\n",
        "        \"https://www.uob.com.sg/online-branch/index.page\",\n",
        "        \"https://www.uobgroup.com/techecosystem\",\n",
        "        \"https://www.uobgroup.com/uobworld/index.page\",\n",
        "        \"https://www.uobam.com.sg/\",\n",
        "        \"https://www.uoi.com.sg/\",\n",
        "        \"https://www.uobgroup.com/sustainability/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/security/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/security/how-uob-protects-you/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/pib/security/index.page#alers-announcements\",\n",
        "        \"https://www.uobgroup.com/uobgroup/contact-us/index.page\",\n",
        "        \"https://www.uob.com.sg/online-branch/locate-us.page\",\n",
        "        \"https://www.uob.com.sg/personal/customer-service/application-forms.page\",\n",
        "        \"https://www.uob.com.sg/personal/chat.page\",\n",
        "        \"https://pib.uob.com.sg/PIBLogin/Public/processPreCapture.do?keyId=lpc\",\n",
        "        \"https://secure.uobam.com.sg/login?lid=uobam-invest-login\",\n",
        "        \"https://ocoe.uob.com.sg/login\",\n",
        "        \"https://pib.uob.com.sg/Rewards/\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/adulting/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/exploring-the-world.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/growing-your-money.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/getting-married.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/starting-a-family.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/life-moments/planning-your-retirement.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/for-the-ladies.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/sustainable-living.page\",\n",
        "        \"https://www.uob.com.sg/personal/solutions/wellness/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/home-and-property/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/drivers-and-commuters.page\",\n",
        "        \"https://www.uob.com.sg/personal/highlights/solutions/index.page\",\n",
        "        \"https://www.uob.com.sg/uobgroup/url-redirection.page?reURL=https://thediningadvisor.com/home\",\n",
        "        \"https://www.uob.com.sg/uobgroup/url-redirection.page?reURL=https://thetravelinsider.co/sg/en\",\n",
        "        \"https://www.uob.com.sg/shopuob\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page?filter=cashback\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page?filter=travel\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page?filter=rewards\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page?filter=privilege\",\n",
        "        \"https://www.uob.com.sg/personal/cards/index.page#debit-cards\",\n",
        "        \"https://www.uob.com.sg/personal/cards/supplementary-card.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/rewards/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/card-privileges/fuel-power-index.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/card-privileges/uob-dollar.page\",\n",
        "        \"https://uob.com.sg/transit\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/payment-facility.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/smart-pay.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/recurring-bill-payment.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/credit-limit-review.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/card-alerts.page\",\n",
        "        \"https://www.uob.com.sg/personal/customer-service/credit-card.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/promotions/cards/sign-up-offers/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/card-activation.page\",\n",
        "        \"https://www.uob.com.sg/personal/cards/services/overseas-card-use.page\",\n",
        "        \"https://forms.uob.com/sg/apply/status\",\n",
        "        \"https://forms.uob.com.sg/property/apply\",\n",
        "        \"https://forms.uob.com.sg/property/calculator/\",\n",
        "        \"https://forms.uob.com.sg/property/valuation/\",\n",
        "        \"https://forms.uob.com.sg/personal/services/carloans/contact-us.html\",\n",
        "        \"https://www.uob.com.sg/personal/invest/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/wealth-insights/index.page#daily-updates\",\n",
        "        \"https://www.uob.com.sg/personal/invest/wealth-insights/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/market-outlook/index.page?i_cid=grm:sg:owned:onl:pweb:na:tx:na:uobins:020724-evergreen:moy:pbinvestdropdown:na&vid=na\",\n",
        "        \"https://www.uob.com.sg/personal/invest/wealth-approach/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/unit-trusts/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/gold-and-silver.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/cpf-investment-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/srs-account.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/sustainable-investing/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/income-builder.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/unit-trusts/fund-selector.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/product-providers.page\",\n",
        "        \"https://www.uob.com.sg/personal/invest/cpfis-srs-corporate-actions-information.page\",\n",
        "        \"https://www.uob.com.sg/web-resources/personal/pdf/personal/best-execution-customer-disclosure.pdf\",\n",
        "        \"https://forms.uob.com.sg/uobforms/POR/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/general/index.page?filter=accidents-and-health\",\n",
        "        \"https://www.uob.com.sg/personal/insure/general/index.page?filter=travel\",\n",
        "        \"https://www.uob.com.sg/personal/insure/general/insuredrive.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/general/index.page?filter=home-and-helper\",\n",
        "        \"https://www.uob.com.sg/personal/insure/general/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/retirement/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/savings.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/protection/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/legacy.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/protection/creditsure-plus.page\",\n",
        "        \"https://www.uob.com.sg/personal/insure/life/pokemon.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/index.page\",\n",
        "        \"https://www.uob.com.sg/personal/digital-banking/paynow.page\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Create a scraper with 5 parallel workers\n",
        "    scraper = UOBScraper(headless=True, max_workers=5)\n",
        "\n",
        "    try:\n",
        "        # First, scrape the main category URLs in parallel\n",
        "        logging.info(\"Scraping main category pages...\")\n",
        "        scraper.scrape_urls(main_urls)\n",
        "\n",
        "        # Then scrape product sections in parallel with deeper crawling\n",
        "        logging.info(\"Starting deep section scraping...\")\n",
        "        scraper.scrape_deep_sections_parallel(deep_urls, max_depth=2)\n",
        "\n",
        "        # Final processing is done in the scrape methods\n",
        "        logging.info(\"Scraping completed successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during scraping: {e}\")\n",
        "    finally:\n",
        "        scraper.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfNp1ejuJ_2u",
        "outputId": "d6846abb-a50e-4c16-f530-40e8379839f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to uob_data/uob_data_cleaned.csv and uob_data/uob_data_cleaned.xlsx\n",
            "Total entries: 4511\n",
            "Total unique URLs scraped: 141\n",
            "Data successfully saved to uob_data/uob_data_cleaned.csv and uob_data/uob_data_cleaned.xlsx\n",
            "Total entries: 4511\n",
            "Total unique URLs scraped: 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGIsFM8Q8mvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}